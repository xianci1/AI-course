#加载必要的库

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.backcompat import keepdim_warning
from torchvision import datasets ,transforms
from unicodedata import digit
import cv2
import torchvision
#定义超参数

BATCH_SIZE=20
EPOCH=10
DEVICE=torch.device("cuda"if torch.cuda.is_available() else "cpu")

#对图像进行处理
pipeline=transforms.Compose([
    transforms.ToTensor(),#将图片转为tensor
    transforms.Normalize((0.1307,),(0.3081,))# 正则化
])

#下载数据集

from torch.utils.data import DataLoader
#下载数据
train_set=datasets.MNIST("data",train=True,download=True,transform=pipeline)
test_set=datasets.MNIST("data",train=False,download=True,transform=pipeline)
#加载数据
train_loader=DataLoader(train_set,batch_size=BATCH_SIZE,shuffle=True)
test_loader=DataLoader(test_set,batch_size=BATCH_SIZE,shuffle=True)

# 实现单张图片可视化
images, labels = next(iter(train_loader))
img = torchvision.utils.make_grid(images)

img = img.numpy().transpose(1, 2, 0)
std = [0.5, 0.5, 0.5]
mean = [0.5, 0.5, 0.5]
img = img * std + mean
print(labels)
cv2.imshow('win', img)
key_pressed = cv2.waitKey(0)

#构筑网络模型
class CNN(nn.Module):
    def __init__(self):
        super(CNN,self).__init__()
        self.conv1=nn.Conv2d(1,10,5)
        self.conv2=nn.Conv2d(10,20,3)
        self.fc1=nn.Linear(20*10*10,500)
        self.fc2=nn.Linear(500,10)

    def forward(self,x):
        input_size=x.size(0) #BATCH_SIZE*1*28*28

        x=self.conv1(x)
        x=F.relu(x) #激活函数
        x=F.max_pool2d(x,2,2)#池化减半

        x=self.conv2(x)
        x=F.relu(x)
        x=x.view(input_size,-1)#拉平,-1自动计算维度

        x=self.fc1(x)
        x=F.relu(x)
        x=self.fc2(x)

        output=F.log_softmax(x,dim=1)
        return output

#定义优化器
model= CNN().to(DEVICE)

optimizer = optim.Adam(model.parameters())

#定义训练方法
def train_model(model,device,train_loader,optimizer,epoch):
    model.train()
    for batch_index,(data,target) in enumerate(train_loader):
        #部署到DEVICE上去
        data,target=data.to(device),target.to(device)
        optimizer.zero_grad()
        output=model(data)
        loss=F.cross_entropy(output,target)
        pred=output.max(1,keepdim=True)
        loss.backward()
        optimizer.step()#参数优化
        if batch_index%3000==0:
            print("EPOCH:{} LOSS:{:.6f}".format(epoch,loss.item()))
            # torch.save(model.state_dict(), "./model.pth")

#定义测试方法
def test_model(model,device,test_loader):
    model.eval()
    #正确率
    correct=0.0
    test_loss=0.0

    with torch.no_grad():
        for data ,target in test_loader:
            data,target=data.to(device),target.to(device)
            output=model(data)
            #计算损失
            test_loss+=F.cross_entropy(output,target)
            #找到概率最大的下标
            pred=output.max(1,keepdim=True)[1]
            correct+=pred.eq(target.view_as(pred)).sum().item()
        test_loss/=len(test_loader.dataset)
        print("test_loss:{:.4f},Accuracy:{:.3f}".format(test_loss,100.0*correct/len(test_loader.dataset)))

for epoch in range(1,EPOCH+1):
    train_model(model,DEVICE,train_loader, optimizer, epoch)
    test_model(model,DEVICE,test_loader)
